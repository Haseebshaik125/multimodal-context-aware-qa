## Literature Review

This folder contains summaries of key research papers related to multimodal
question answering and vision-language models.

### Key Papers
1. CLIP – Learning Transferable Visual Models from Natural Language
2. ViLBERT – Pretraining Task-Agnostic Visiolinguistic Representations
3. Flamingo – A Visual Language Model for Few-Shot Learning
4. BLIP – Bootstrapping Language-Image Pre-training

### Focus Areas
- Multimodal fusion strategies
- Cross-attention mechanisms
- Dataset biases and limitations
